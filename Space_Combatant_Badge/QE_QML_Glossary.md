### QML Glossary

**Accuracy**: a metric used to evaluate the performance of your machine learning model calculated by measuring the sum of the ratio between correct predictions and all the predictions. 

**Amplitude encoding**: a way to store data within the amplitude of a quantum state.

**Class imbalance**: when a classification dataset has skewed proportions, for example in a binary classification dataset but one class has twice as many data points as the other class.

**Classification**: a type of supervised machine learning problem where a model predicts a particular class label for an input data point.

**Clustering**: a type of unsupervised machine learning where a model tries to find patterns in data to collect together groups or clusters in the feature space.

**Covariance matrix**: a matrix used in PCA representing the covariances associated with all possible pairs of variables.

**Data mining**: analysing data including extracting data and finding patterns within it.

**Dependent variable**: the variable that is being tested within an experiment or machine learning model.

**Dimensionality reduction**: the technique of transforming data with a large number of dimensions to a lower number of dimensions. An example technique is PCA.

**Eigenvectors and eigenvalues**: a set of scalar values that are associated with a set of linear equations. See here for more info https://www.youtube.com/watch?v=PFDu9oVAE-g

**Fourier transform**: a mathematical transformation that decomposes functions into sine and cosine components. There are many applications of the Fourier transform within signal processing, physics, engineering and much more.

**Hilbert space**: a vector space that is complete with respect to the norm given by the inner product. See here for more info https://www.youtube.com/watch?v=7zx3MT9FgT0

**Independent variable**: a variable that you control in an experiment that isn’t influenced by other factors of the experiment, such as a person’s age.

**K nearest neighbours**: a supervised learning classifier that uses distance metrics to calculate the nearest neighbours of a particular data point in order to classify the class it may belong to.

**Mean squared error (MSE)**: the average squared difference between the actual and predicted values. The lower the MSE the better.

**Over fitting**: when a model fits the training data so well that it is unable to generalise to the testing data.

**Principal component analysis (PCA)**: a method of dimensionality reduction that uses the first few principal vectors to perform a change of basis on the data.

**Quantum random access memory (QRAM)**: similar to classical RAM, it is data storage that can be read and changed in any order but also allows the storage of quantum states.

**R2 score**: the coefficient of determination is an evaluation metric for regression that is the amount of variation in the output dependent variable to the input independent variable.

**Regression**: a type of supervised machine learning where the model looks for a relationship between independent variable/s and a dependent variable. There are different types of regression such as linear regression, logistic regression and polynomial regression.

**Reinforcement learning**: an area of machine learning that uses a training method based on rewarding desired actions and/or punishing undesired ones.

**Supervised learning**: a category of machine learning that trains models using labelled input datasets.

**Support vector machine (SVM)**: a type of supervised machine learning that can be used for both classification and regression problems. See here for more info https://scikit-learn.org/stable/modules/svm.html

**Under fitting**: when a model is unable to capture a relationship between the input training variables and thus cannot form a strong enough relationship to predict any new data accurately as well.

**Unsupervised learning**: a category of machine learning that trains models using unlabelled input datasets. 

